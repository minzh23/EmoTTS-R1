  0%|                                                                                | 0/264 [00:00<?, ?it/s]Error executing job with overrides: ['++model_config.llm_name=qwen2.5-0.5b', '++model_config.llm_path=/root/EmoVoice/checkpoint/Qwen2.5-0.5B', '++model_config.llm_dim=896', '++model_config.codec_decoder_path=/root/EmoVoice/checkpoint/CosyVoice', '++model_config.codec_decode=true', '++model_config.vocab_config.code_layer=3', '++model_config.vocab_config.total_audio_vocabsize=4160', '++model_config.vocab_config.total_vocabsize=156160', '++model_config.codec_decoder_type=CosyVoice', '++model_config.group_decode=true', '++model_config.group_decode_adapter_type=linear', '++model_config.use_text_stream=false', '++dataset_config.dataset=speech_dataset_tts', '++dataset_config.val_data_path=/root/EmoVoice/EmoVoice-DB/test.jsonl', '++dataset_config.train_data_path=/root/EmoVoice/EmoVoice-DB/test.jsonl', '++dataset_config.inference_mode=true', '++dataset_config.vocab_config.code_layer=3', '++dataset_config.vocab_config.total_audio_vocabsize=4160', '++dataset_config.vocab_config.total_vocabsize=156160', '++dataset_config.num_latency_tokens=0', '++dataset_config.do_layershift=false', '++dataset_config.use_emo=true', '++train_config.model_name=tts', '++train_config.freeze_encoder=true', '++train_config.freeze_llm=true', '++train_config.freeze_group_decode_adapter=true', '++train_config.batching_strategy=custom', '++train_config.num_epochs=1', '++train_config.val_batch_size=1', '++train_config.num_workers_dataloader=2', '++train_config.max_prompt_length=2048', '++train_config.max_completion_length=768', '++train_config.num_generations=8', '++decode_config.text_repetition_penalty=1.2', '++decode_config.audio_repetition_penalty=1.2', '++decode_config.max_new_tokens=3000', '++decode_config.do_sample=false', '++decode_config.top_p=1.0', '++decode_config.top_k=0', '++decode_config.temperature=1.0', '++decode_config.decode_text_only=false', '++decode_config.num_latency_tokens=0', '++decode_config.do_layershift=false', '++decode_log=/root/EmoVoice/checkpoint/tts_decode_test_rp_seed_greedy_kaiyuan', '++ckpt_path=/root/EmoVoice/checkpoint/EmoVoice.pt', '++output_text_only=false', '++speech_sample_rate=22050', '++log_config.log_file=/root/EmoVoice/checkpoint/tts_decode_test_rp_seed_greedy_kaiyuan/infer.log']
Traceback (most recent call last):
  File "/root/EmoVoice/examples/tts/grpo_tts.py", line 175, in main_hydra
    main(cfg)
  File "/root/EmoVoice/examples/tts/grpo_tts.py", line 249, in main
    trainer.train()
  File "/root/miniconda3/envs/EmoVoice/lib/python3.10/site-packages/transformers/trainer.py", line 2122, in train
    return inner_training_loop(
  File "/root/miniconda3/envs/EmoVoice/lib/python3.10/site-packages/transformers/trainer.py", line 2474, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/root/miniconda3/envs/EmoVoice/lib/python3.10/site-packages/transformers/trainer.py", line 3572, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/root/EmoVoice/examples/tts/grpo_trainer.py", line 394, in compute_loss
    prompts = [x["prompt"] for x in inputs]
  File "/root/EmoVoice/examples/tts/grpo_trainer.py", line 394, in <listcomp>
    prompts = [x["prompt"] for x in inputs]
KeyError: 'prompt'

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
