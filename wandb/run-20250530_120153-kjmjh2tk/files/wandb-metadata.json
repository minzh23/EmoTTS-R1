{
  "os": "Linux-5.15.0-136-generic-x86_64-with-glibc2.35",
  "python": "3.10.16",
  "startedAt": "2025-05-30T04:01:53.943947Z",
  "args": [
    "hydra.run.dir=/root/EmoVoice/checkpoint",
    "++model_config.llm_name=qwen2.5-0.5b",
    "++model_config.llm_path=/root/EmoVoice/checkpoint/Qwen2.5-0.5B",
    "++model_config.llm_dim=896",
    "++model_config.codec_decoder_path=/root/EmoVoice/checkpoint/CosyVoice",
    "++model_config.codec_decode=true",
    "++model_config.vocab_config.code_layer=3",
    "++model_config.vocab_config.total_audio_vocabsize=4160",
    "++model_config.vocab_config.total_vocabsize=156160",
    "++model_config.codec_decoder_type=CosyVoice",
    "++model_config.group_decode=true",
    "++model_config.group_decode_adapter_type=linear",
    "++model_config.use_text_stream=false",
    "++dataset_config.dataset=speech_dataset_tts",
    "++dataset_config.val_data_path=/root/EmoVoice/EmoVoice-DB/test.jsonl",
    "++dataset_config.train_data_path=/root/EmoVoice/EmoVoice-DB/test.jsonl",
    "++dataset_config.inference_mode=true",
    "++dataset_config.vocab_config.code_layer=3",
    "++dataset_config.vocab_config.total_audio_vocabsize=4160",
    "++dataset_config.vocab_config.total_vocabsize=156160",
    "++dataset_config.num_latency_tokens=0",
    "++dataset_config.do_layershift=false",
    "++dataset_config.use_emo=true",
    "++train_config.model_name=tts",
    "++train_config.freeze_encoder=true",
    "++train_config.freeze_llm=true",
    "++train_config.freeze_group_decode_adapter=true",
    "++train_config.batching_strategy=custom",
    "++train_config.num_epochs=1",
    "++train_config.val_batch_size=1",
    "++train_config.num_workers_dataloader=2",
    "++train_config.max_prompt_length=2048",
    "++train_config.max_completion_length=768",
    "++train_config.num_generations=8",
    "++decode_config.text_repetition_penalty=1.2",
    "++decode_config.audio_repetition_penalty=1.2",
    "++decode_config.max_new_tokens=3000",
    "++decode_config.do_sample=false",
    "++decode_config.top_p=1.0",
    "++decode_config.top_k=0",
    "++decode_config.temperature=1.0",
    "++decode_config.decode_text_only=false",
    "++decode_config.num_latency_tokens=0",
    "++decode_config.do_layershift=false",
    "++decode_log=/root/EmoVoice/checkpoint/tts_decode_test_rp_seed_greedy_kaiyuan",
    "++ckpt_path=/root/EmoVoice/checkpoint/EmoVoice.pt",
    "++output_text_only=false",
    "++speech_sample_rate=22050",
    "++log_config.log_file=/root/EmoVoice/checkpoint/tts_decode_test_rp_seed_greedy_kaiyuan/infer.log"
  ],
  "program": "/root/EmoVoice/examples/tts/grpo_tts.py",
  "codePath": "examples/tts/grpo_tts.py",
  "git": {
    "remote": "git@github.com:minzh23/DL-Project.git",
    "commit": "3f044dd2665f919483772d64acf8f769b4d0eff4"
  },
  "email": "minzh23@mails.tsinghua.edu.cn",
  "root": "/root/EmoVoice",
  "host": "autodl-container-fb9d4aa493-a33c0301",
  "username": "root",
  "executable": "/root/miniconda3/envs/EmoVoice/bin/python",
  "codePathLocal": "examples/tts/grpo_tts.py",
  "cpu_count": 64,
  "cpu_count_logical": 128,
  "gpu": "[NVIDIA GeForce RTX 3090]",
  "gpu_count": 1,
  "disk": {
    "/": {
      "total": "32212254720",
      "used": "30407512064"
    }
  },
  "memory": {
    "total": "810961113088"
  },
  "cpu": {
    "count": 64,
    "countLogical": 128
  },
  "gpu_nvidia": [
    {
      "name": "NVIDIA GeForce RTX 3090",
      "memoryTotal": "25769803776",
      "cudaCores": 10496,
      "architecture": "Ampere"
    }
  ],
  "cudaVersion": "12.8"
}